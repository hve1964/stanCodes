---
title: "An Introduction to Inductive Statistical Inference --- Worked examples
  in statistical modelling using R and Stan"
author: "Henk van Elst"
date: "August 30, 2022"
output:
  html_notebook:
    number_sections: yes
    toc: yes
---
  
```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

... Gabry *et al* (2019), visualisation in Bayesian workflow

# Load packages

R packages `rstan` by the Stan Development Team (2022b), `bayesplot` by
Gabry and Mahr (2022), `loo` by Vehtari *et al* (2022),
`tidyverse` by Wickham *et al* (2019), `magrittr` by
Bache and Wickham (2022), `GGally` by Schloerke *et al* (2021),
`lubridate` by Grolemund and Wickham (2011) ...

```{r libraries, echo = TRUE}
library(bayesplot)
library(GGally)
library(loo)
library(lubridate)
library(magrittr)
library(rstan)
library(scales)
library(tidyverse)
options(mc.cores = parallel::detectCores())
rstan::rstan_options("required" = FALSE)
rstan::rstan_options(auto_write = TRUE)
rstan::stan_version()
```

# Fixed effects generalised linear models

## Linear regression

### Data, visualisation and research question

**data set** `ashenfelter.RData` by Ashenfelter, Ashmore and Lalonde, URL (cited
on August 17, 2022): http://www.liquidasset.com/); cf. Kahneman (2011),
removal of NAs

```{r dataLinRegNormFixed}
load("ashenfelter.RData")
attach(what = ashenfelter)
any(is.na(x = ashenfelter)) # Checking for missing values in the data matrix
dat <-
  stats::na.omit(object = ashenfelter) %>% # Delete cases with missing values
  tibble::as_tibble(x = .)
rm(ashenfelter)
dim(x = dat)
head(x = dat)
```

**standardisation** of **variables**

`y`: standardised logarithm of average vintage wine price relative to 1961
vintage [1] (`LPRICE2`)

`x1`: standardised winter (October-March) rain [ml] (`WRAIN`)

`x2`: standardised average temperature April-September [°C] (`DEGREES`)

`x3`: standardised harvest (August and September) rain [ml] (`HRAIN`)

`x4`: standardised time since vintage [yr] (zero-point year: 1983) (`TIME_SV`)

```{r standLinRegNormFixed}
Z <-
  scale(x = dat[, 3:7],
        center = TRUE,
        scale = TRUE) %>%
  magrittr::set_colnames(x = ., value = c("y", "x1", "x2", "x3", "x4")) %>%
  tibble::as_tibble(x = .)
head(x = Z)
```

**visualisation** 

```{r visLinRegNormFixed}
Z %>%
  GGally::ggpairs(data = ., title = "Scatter plot matrix") +
  ggplot2::theme_bw()
```

**design matrix**

```{r designLinRegNormFixed}
X <-
  unname(stats::model.matrix(object = y ~ 1 + x1 + x2 + x3 + x4,
                             data = Z))
attr(x = X, which = "assign") <- NULL
head(x = X)
```

data list for Stan simulation

```{r listLinRegNormFixed}
dataList <-
  list(
    N = nrow(x = X),
    M = ncol(x = X),
    X = as.matrix(x = X),
    y = as.numeric(x = Z$y)
  )
rm(dat, X, Z)
```

### Statistical model

**model parameters** $\boldsymbol{\beta}$ and $\sigma$

\[
\text{Likelihood:}  \qquad
\left.\boldsymbol{y}\right| \boldsymbol{X}, \boldsymbol{\beta},
\sigma^{2}, I
\stackrel{\mathrm{ind}}{\sim} \mathrm{N}(\mu, \sigma^{2}) \ ,
\qquad
\sigma^{2} := \mathrm{Var}\left(\left.\boldsymbol{y}\right| \boldsymbol{X}, \boldsymbol{\beta}, I\right) = \text{constant}
\]
\[
\text{Linear model:} \qquad
\mu := \mathrm{E}\left(\left.\boldsymbol{y}\right| \boldsymbol{X}, 
\boldsymbol{\beta}, \sigma^{2}, I\right) = \boldsymbol{X}\boldsymbol{\beta}
\]
\[
\text{Regularising fixed priors:} \qquad
\left.\boldsymbol{\beta} \right| \sigma^{2}, I
\sim \mathrm{N}(0, 1) \ ,
\qquad \left.\sigma\right| I
\sim \mathrm{Exp}(1)
\]

### Fitting a Stan model: Gauß likelihood and regularising fixed priors

```{r stanLinRegNormFixed}
stanLinRegNormFixed <-
  rstan::stan(
    file = "linRegNormFixed.stan",
    data = dataList,
    chains = 4,
    iter = 2000,
    warmup = 1000,
    thin = 1,
    init = "random",
    algorithm = "NUTS",
    control = list(adapt_delta = 0.99,
                   max_treedepth = 15),
    cores = 3
  )
```

See also the Stan User's Guide (Version 2.30), Sec. 1.1, URL (cited on
August 19, 2022): 
https://mc-stan.org/docs/stan-users-guide/linear-regression.html.

### HMC diagnostics

```{r diagnLinRegNormFixed}
rstan::check_hmc_diagnostics(object = stanLinRegNormFixed)
rstan::stan_trace(
  object = stanLinRegNormFixed,
  pars = c("beta", "sigma", "lp__"),
  inc_warmup = TRUE
)
```

### Summary of posterior marginal probability distributions for model parameters

```{r summaryLinRegNormFixed}
print(
  x = stanLinRegNormFixed,
  pars = c("beta", "sigma", "lp__"),
  probs = c(0.015, 0.25, 0.50, 0.75, 0.985)
)
rstan::stan_plot(
  object = stanLinRegNormFixed,
  pars = c("beta", "sigma"),
  ci_level = 0.89,
  outer_level = 0.97
)
rstan::stan_dens(object = stanLinRegNormFixed,
                 pars = c("beta", "sigma", "lp__"))
```

### Posterior predictive checks

```{r ppcLinRegNormFixed}
draws <-
  as.matrix(x = stanLinRegNormFixed,
            pars = "yrep")

bayesplot::ppc_dens_overlay(y = dataList$y,
                            yrep = draws[501:600,]) +
  ggplot2::labs(
    title = paste0(
      "Posterior predictive distribution ",
      "(re-using predictor data)"
    ),
    subtitle = "Empirical density overlaid with 100 HMC samples"
  ) +
  ggplot2::xlab(label = "Standardised y [1]") +
  ggplot2::ylab(label = "Density [1]") +
  ggplot2::theme_bw()

bayesplot::ppc_intervals(
  y = dataList$y,
  yrep = draws,
  prob = 0.89,
  prob_outer = 0.97,
  size = 1,
  fatten = 3
) +
  ggplot2::labs(
    title = paste0(
      "Posterior predictive compatibility intervals ",
      "(re-using predictor data)"
    ),
    subtitle = "Data points overlaid with interval estimates"
  ) +
  ggplot2::xlab(label = "Sample number") +
  ggplot2::ylab(label = "Standardised y [1]") +
  ggplot2::theme_bw()
```

### Analysis of residuals

Berechnen aus den HMC-simulierten Daten der Bayes-Laplace'schen **Residuen**
für die **statistische Variable** `y` zu den gemessenen Werten für
`x1`, `x2`, x3` and `x4`. Hierfür wird der Stichprobenmittelwert
der HMC-simulierten Verteilungen für die prognostizierten Werte `yrep`
verwendet.

```{r residLinRegNormFixed}
tibble::tibble(
  predicted = draws %>%
    tibble::as_tibble(x = .) %>%
    purrr::map_dbl(.x = ., .f = mean, na.rm = TRUE),
  observed = dataList$y
) %>%
  dplyr::mutate(.data = .,
                residuals = (observed - predicted)) %>%
  dplyr::mutate(
    .data = .,
    residuals_std = scale(x = residuals,
                          center = TRUE,
                          scale = TRUE) %>%
      as.numeric(x = .)
  ) %>%
  ggplot2::ggplot(data = .,
         mapping = aes(x = predicted, y = residuals_std)) +
  ggplot2::geom_point() +
  ggplot2::geom_hline(yintercept = 0, size = 0.4) +
  ggplot2::geom_vline(xintercept = 0, size = 0.4) +
  ggplot2::labs(title = "Analysis of residuals: residual scatter plot") +
  ggplot2::xlab(label = "Predicted y-values [1]") +
  ggplot2::ylab(label = "Standardised residuals [1]") +
  ggplot2::theme_bw()
```

### Remarks

clear data
```{r clearLinRegNormFixed}
rm(dataList, draws, stanLinRegNormFixed)
```

## ANOVA-like regression

### Data, visualisation and research question

**data set** `massMonitoring.csv`

```{r dataAnovaRegNormFixed}
dat <-
  utils::read.csv(file = "massMonitoring.csv") %>%
  tibble::as_tibble(x = .)
any(is.na(x = dat))
dim(x = dat)
head(x = dat)
```

**variables**

`y`: body mass [kg] (`X1`)

`gp`: year of observation (`X2`)

**visualisation**

```{r visAnovaRegNormFixed}
dat %>%
  ggplot2::ggplot(data = ., mapping = aes(x = as.factor(x = X2), y = X1)) +
  ggplot2::geom_boxplot() +
  ggplot2::xlab(label = "Year of observation") +
  ggplot2::ylab(label = "Body mass [kg]") +
  ggplot2::theme_bw()
```

data list for Stan simulation

```{r listAnovaRegNormFixed}
dataList <-
  list(
    N = as.integer(x = nrow(x = dat)),
    K = length(x = unique(x = dat$X2)),
    gp = dat$X2,
    y = dat$X1
  )
rm(dat)
```

### Statistical model

**model parameters** $\boldsymbol{\mu}[gp]$ and $\sigma$

\[
\text{Likelihood:}  \qquad
\left.\boldsymbol{y}\right| \boldsymbol{\mu},
\sigma^{2}, [gp], I
\stackrel{\mathrm{ind}}{\sim} \mathrm{N}(\boldsymbol{\mu}[gp], \sigma^{2}) \ ,
\qquad
\sigma^{2} := \mathrm{Var}\left(\left.\boldsymbol{y}\right| I\right) = 
\text{constant}
\]
\[
\text{Fixed priors:} \qquad
\left.\boldsymbol{\mu}[gp] \right| \sigma^{2}, I
\sim \mathrm{N}(90~\mathrm{kg}, (2~\mathrm{kg})^{2}) \ ,
\qquad \left.\sigma\right| I
\sim \mathrm{Exp}(1)
\]

### Fitting a Stan model: Gauß likelihood, homogeneous variances and fixed priors

```{r stanAnovaRegNormFixed}
stanAnovaRegNormFixed <-
  rstan::stan(
    file = "anovaRegNormFixed.stan",
    data = dataList,
    chains = 4,
    iter = 2000,
    warmup = 1000,
    thin = 1,
    init = "random",
    algorithm = "NUTS",
    control = list(adapt_delta = 0.99,
                   max_treedepth = 15),
    cores = 3
  )
```

### HMC diagnostics

```{r diagnAnovaRegNormFixed}
rstan::check_hmc_diagnostics(object = stanAnovaRegNormFixed)
rstan::stan_trace(
  object = stanAnovaRegNormFixed,
  pars = c("mu", "sigma", "lp__"),
  inc_warmup = TRUE
)
```

### Summary of posterior marginal probability distributions for model parameters

```{r summaryAnovaRegNormFixed}
print(
  x = stanAnovaRegNormFixed,
  pars = c("mu", "sigma", "lp__"),
  probs = c(0.015, 0.25, 0.50, 0.75, 0.985)
)
rstan::stan_plot(
  object = stanAnovaRegNormFixed,
  pars = c("mu"),
  ci_level = 0.89,
  outer_level = 0.97
)
rstan::stan_plot(
  object = stanAnovaRegNormFixed,
  pars = c("sigma"),
  ci_level = 0.89,
  outer_level = 0.97
)
rstan::stan_dens(object = stanAnovaRegNormFixed,
                 pars = c("mu", "sigma", "lp__"))
```

### Posterior predictive checks

```{r ppcAnovaRegNormFixed}
draws <-
  as.matrix(x = stanAnovaRegNormFixed,
            pars = "yrep")

bayesplot::ppc_dens_overlay(y = dataList$y,
                            yrep = draws[501:600,]) +
  ggplot2::labs(
    title = paste0(
      "Posterior predictive distribution ",
      "(re-using predictor data)"
    ),
    subtitle = "Empirical density overlaid with 100 HMC samples"
  ) +
  ggplot2::xlab(label = "y [kg]") +
  ggplot2::ylab(label = "Density [1/kg]") +
  ggplot2::theme_bw()

bayesplot::ppc_intervals_grouped(
  y = dataList$y,
  yrep = draws,
  group = dataList$gp,
  prob = 0.89,
  prob_outer = 0.97,
  size = 1,
  fatten = 3
) +
  ggplot2::labs(
    title = paste0(
      "Posterior predictive compatibility intervals ",
      "(re-using predictor data)"
    ),
    subtitle = "Data points overlaid with interval estimates"
  ) +
  ggplot2::xlab(label = "Sample number") +
  ggplot2::ylab(label = "y [kg]") +
  ggplot2::theme_bw()
```

### Remarks

clear data
```{r clearAnovaRegNormFixed}
rm(dataList, draws, stanAnovaRegNormFixed)
```

## Logistic regression

### Data, visualisation and research question

**data set** `urine` from R package `boot` by Canty and Ripley (2021).

```{r dataLogistRegBernFixed}
library(boot)
data("urine")
attach(what = urine)
any(is.na(x = urine)) # Checking for missing values in the data matrix
dat <-
  stats::na.omit(object = urine) %>% # Delete cases with missing values
  tibble::as_tibble(x = .)
rm(urine)
dim(x = dat)
head(x = dat)
```

**visualisation** (suppressing five independent variables other than `urea`)

```{r visLogistRegBernFixed}
dat %>%
  ggplot2::ggplot(data = ., mapping = aes(x = urea, y = r)) +
  ggplot2::geom_point() +
  ggplot2::scale_x_continuous(name = paste0("Urea concentration ",
                                            "[millimoles per litre]")) +
  ggplot2::scale_y_continuous(
    name = "Presence of calcium oxalate crystals [1]",
    breaks = seq(from = 0, to = 1, by = 1),
    labels = scales::number_format(
      accuracy = 1,
      big.mark = ".",
      decimal.mark = ","
    )
  ) +
  ggplot2::theme_bw()
```

**standardisation** of **variables**

`y`: indicator of the presence of calcium oxalate crystals: {0, 1} (`r``)

`x1`: standardised specific gravity of the urine [1] (`gravity`)

`x2`: standardised pH reading of the urine [1] (`ph`)

`x3`: standardised osmolarity of the urine [milliosmoles per litre] (`osmo`)

`x4`: standardised conductivity of the urine [micro-Siemens per centimetre] 
(`cond`)

`x5`: standardised urea concentration [millimoles per litre] (`urea`)

`x6`: standardised calcium concentration [millimoles per litre] (`calc`)

```{r standLogistRegBernFixed}
Z <-
  scale(x = dat[, 2:7],
        center = TRUE,
        scale = TRUE) %>%
  magrittr::set_colnames(x = .,
                         value = c("x1", "x2", "x3", "x4", "x5", "x6")) %>%
  tibble::as_tibble(x = .)
head(x = Z)
```

**design matrix**

```{r designLogistRegBernFixed}
X <-
  unname(stats::model.matrix(object = dat$r ~ 1 + x1 + x2 + x3 + x4 + x5 + x6,
                             data = Z))
attr(x = X, which = "assign") <- NULL
head(x = X)
```

data list for Stan simulation

```{r listLogistRegBernFixed}
dataList <-
  list(
    N = nrow(x = X),
    M = ncol(x = X),
    X = as.matrix(x = X),
    y = as.integer(x = dat$r)
  )
rm(dat, X, Z)
```

### Statistical model

**model parameters** $\boldsymbol{\beta}$

\[
\text{Likelihood:}  \qquad
\left.\boldsymbol{y}\right| \boldsymbol{X}, \boldsymbol{\beta}, I
\stackrel{\mathrm{ind}}{\sim} \mathrm{Bern}(p)
\]
\[
\text{Linear model:} \qquad
\text{logit}(p) := \ln\left(\frac{p}{1-p}\right)
= \boldsymbol{X}\boldsymbol{\beta}
\]
\[
\text{Regularising fixed priors:} \qquad
\left.\boldsymbol{\beta} \right| I
\sim \mathrm{N}(0, 1)
\]

### Fitting a Stan model: Bernoulli likelihood with logit link and regularising fixed priors

```{r stanLogistRegBernFixed}
stanLogistRegBernFixed <-
  rstan::stan(
    file = "logistRegBernFixed.stan",
    data = dataList,
    chains = 4,
    iter = 2000,
    warmup = 1000,
    thin = 1,
    init = "random",
    algorithm = "NUTS",
    control = list(adapt_delta = 0.99,
                   max_treedepth = 15),
    cores = 3
  )
```

See also the Stan User's Guide (Version 2.30), Sec. 1.1, URL (cited on
August 19, 2022): 
https://mc-stan.org/docs/stan-users-guide/logistic-probit-regression.html.

### HMC diagnostics

```{r diagnLogistRegBernFixed}
rstan::check_hmc_diagnostics(object = stanLogistRegBernFixed)
rstan::stan_trace(
  object = stanLogistRegBernFixed,
  pars = c("beta", "lp__"),
  inc_warmup = TRUE
)
```

### Summary of posterior marginal probability distributions for model parameters

```{r summaryLogistRegBernFixed}
print(
  x = stanLogistRegBernFixed,
  pars = c("beta", "lp__"),
  probs = c(0.015, 0.25, 0.50, 0.75, 0.985)
)
rstan::stan_plot(
  object = stanLogistRegBernFixed,
  pars = c("beta"),
  ci_level = 0.89,
  outer_level = 0.97
)
rstan::stan_dens(object = stanLogistRegBernFixed,
                 pars = c("beta", "lp__"))
```

### Posterior predictive checks

```{r ppcLogistRegBernFixed}
draws <-
  as.matrix(x = stanLogistRegBernFixed,
            pars = "yrep")

bayesplot::ppc_dens_overlay(y = dataList$y,
                            yrep = draws[501:600,]) +
  ggplot2::labs(
    title = paste0(
      "Posterior predictive distribution ",
      "(re-using predictor data)"
    ),
    subtitle = "Empirical density overlaid with 100 HMC samples"
  ) +
  ggplot2::xlab(label = "y [1]") +
  ggplot2::ylab(label = "Density [1]") +
  ggplot2::theme_bw()

bayesplot::ppc_intervals(
  y = dataList$y,
  yrep = draws,
  prob = 0.89,
  prob_outer = 0.97,
  size = 1,
  fatten = 3
) +
  ggplot2::labs(
    title = paste0(
      "Posterior predictive compatibility intervals ",
      "(re-using predictor data)"
    ),
    subtitle = "Data points overlaid with interval estimates"
  ) +
  ggplot2::xlab(label = "Sample number") +
  ggplot2::ylab(label = "y [1]") +
  ggplot2::theme_bw()
```

### Remarks

clear data
```{r clearLogistRegBernFixed}
rm(dataList, draws, stanLogistRegBernFixed)
```

## Poisson regression

### Data, visualisation and research question

**data set** `poissonData.RData`

```{r dataPoisRegFixed}
load("poissonData.RData")
attach(what = poissonData)
any(is.na(x = poissonData)) # Checking for missing values in the data matrix
dat <-
  stats::na.omit(object = poissonData) %>% # Delete cases with missing values
  tibble::as_tibble(x = .)
rm(poissonData)
dim(x = dat)
head(x = dat)
```

**visualisation**

```{r visPoisRegFixed}
dat %>%
  ggplot2::ggplot(data = ., mapping = aes(x = y)) +
  ggplot2::geom_bar(mapping = aes(y = ..prop..),
                    stat = "count",
                    width = 0.1) +
  ggplot2::scale_x_continuous(
    name = "Count per 15 min observation interval [1]",
    breaks = seq(from = 0, to = 8, by = 1),
    labels = scales::number_format(
      accuracy = 1,
      big.mark = ".",
      decimal.mark = ","
    )
  ) +
  ggplot2::scale_y_continuous(
    name = "Relative frequency [1]",
    labels = scales::percent) +
  ggplot2::theme_bw()
```

**standardisation** of **variables**

`y`: count of planes touching down inside of a 15 min observation interval [1]

`x1`: standardised start of 15 min observation interval [h]

`x2`: standardised estimated Beaufort wind force scale number [1]

`x3`: standardised wind direction [1]

`gp`: day-of-week ID: Monday (`1`) to Sunday (`7`)

```{r standPoisRegFixed}
Z <-
  scale(x = dat[, 2:4],
        center = TRUE,
        scale = TRUE) %>%
  magrittr::set_colnames(x = ., value = c("x1", "x2", "x3")) %>%
  tibble::as_tibble(x = .)
head(x = Z)
```

**design matrix**

```{r designPoisRegFixed}
X <-
  unname(stats::model.matrix(object = dat$y ~ 1 + x1 + x2 + x3,
                             data = Z))
attr(x = X, which = "assign") <- NULL
head(x = X)
```

data list for Stan simulation

```{r listPoisRegFixed}
dataList <-
  list(
    N = nrow(x = X),
    M = ncol(x = X),
    X = X,
    y = dat$y
  )
rm(dat, X, Z)
```

### Statistical model

**model parameters** $\boldsymbol{\beta}$

\[
\text{Likelihood:}  \qquad
\left.\boldsymbol{y}\right| \boldsymbol{X}, \boldsymbol{\beta}, I
\stackrel{\mathrm{ind}}{\sim} \mathrm{Pois}(\theta)
\]
\[
\text{Linear model:} \qquad
\ln\left(\theta\right)
= \boldsymbol{X}\boldsymbol{\beta}
\]
\[
\text{Regularising fixed priors:} \qquad
\left.\boldsymbol{\beta} \right| I
\sim \mathrm{N}(0, 1)
\]


### Fitting a Stan model: Poisson likelihood with log link and regularising fixed priors

```{r stanPoisRegFixed}
stanPoisRegFixed <-
  rstan::stan(
    file = "poisRegFixed.stan",
    data = dataList,
    chains = 4,
    iter = 2000,
    warmup = 1000,
    thin = 1,
    init = "random",
    algorithm = "NUTS",
    control = list(adapt_delta = 0.99,
                   max_treedepth = 15),
    cores = 3
  )
```

### HMC diagnostics

```{r diagnPoisRegFixed}
rstan::check_hmc_diagnostics(object = stanPoisRegFixed)
rstan::stan_trace(
  object = stanPoisRegFixed,
  pars = c("beta", "lp__"),
  inc_warmup = TRUE
)
```

### Summary of posterior marginal probability distributions for model parameters

```{r summaryPoisRegFixed}
print(
  x = stanPoisRegFixed,
  pars = c("beta", "lp__"),
  probs = c(0.015, 0.25, 0.50, 0.75, 0.985)
)
rstan::stan_plot(
  object = stanPoisRegFixed,
  pars = c("beta"),
  ci_level = 0.89,
  outer_level = 0.97
)
rstan::stan_dens(object = stanPoisRegFixed,
                 pars = c("beta", "lp__"))
```

### Posterior predictive checks

```{r ppcPoisRegFixed}
draws <-
  as.matrix(x = stanPoisRegFixed,
            pars = "yrep")

bayesplot::ppc_dens_overlay(y = dataList$y,
                            yrep = draws[501:600,]) +
  ggplot2::labs(
    title = paste0(
      "Posterior predictive distribution ",
      "(re-using predictor data)"
    ),
    subtitle = "Empirical density overlaid with 100 HMC samples"
  ) +
  ggplot2::ylab(label = "Density [1]") +
  ggplot2::scale_x_continuous(
    name = "y [1]",
    breaks = seq(from = 0, to = 8, by = 1),
    labels = scales::number_format(
      accuracy = 1,
      big.mark = ".",
      decimal.mark = ","
    )
  ) +
  ggplot2::theme_bw()

bayesplot::ppc_intervals(
  y = dataList$y,
  yrep = draws,
  prob = 0.89,
  prob_outer = 0.97,
  size = 1,
  fatten = 3
) +
  ggplot2::labs(
    title = paste0(
      "Posterior predictive compatibility intervals ",
      "(re-using predictor data)"
    ),
    subtitle = "Data points overlaid with interval estimates"
  ) +
  ggplot2::xlab(label = "Sample number") +
  ggplot2::ylab(label = "y [1]") +
  ggplot2::theme_bw()

bayesplot::ppc_rootogram(
  y = dataList$y,
  yrep = draws,
  style = "standing",
  prob = 0.89,
  size = 1
) +
  ggplot2::labs(title = "Rootogram") +
  ggplot2::theme_bw()
```

### Remarks

clear data
```{r clearPoisRegFixed}
rm(dataList, draws, stanPoisRegFixed)
```

## Exponential regression

### Data, visualisation and research question

**data set** `tramWait.RData`

```{r dataExpRegFixed}
load("tramWait.RData")
attach(what = tramWait)
any(is.na(x = tramWait)) # Checking for missing values in the data matrix
dat <-
  stats::na.omit(object = tramWait) %>%  # Delete cases with missing values
  tibble::as_tibble(x = .)
rm(tramWait)
dim(x = dat)
head(x = dat)
```

**standardisation** of **variables**

`y`: waiting time for tram to arrive at stop [min] (`wait`)

`x1`: standardised number of tram conductors available on tram line on day of 
observation [1] (`conductors`)

`x2`: standardised number of passengers having left or entered tram at previous 
stops [1] (`passChanged`)

`gp`: tram line number (`1` to `10`) (`tram`)

```{r standExpRegFixed}
Z <-
  scale(x = dat[, 2:3],
        center = TRUE,
        scale = TRUE) %>%
  magrittr::set_colnames(x = ., value = c("x1", "x2")) %>%
  tibble::as_tibble(x = .)
head(x = Z)
```

**design matrix**

```{r designExpRegFixed}
X <-
  unname(stats::model.matrix(object = dat$wait ~ 1 + x1 + x2,
                             data = Z))
attr(x = X, which = "assign") <- NULL
head(x = X)
```

data list for Stan simulation

```{r listExpRegFixed}
dataList <-
  list(
    N = nrow(x = X),
    M = ncol(x = X),
    X = X,
    y = dat$wait
  )
rm(dat, X, Z)
```

### Statistical model

**model parameters** $\boldsymbol{\beta}$

\[
\text{Likelihood:}  \qquad
\left.\boldsymbol{y}\right| \boldsymbol{X}, \boldsymbol{\beta}, I
\stackrel{\mathrm{ind}}{\sim} \mathrm{Exp}(\theta)
\]
\[
\text{Linear model:} \qquad
\ln\left(\theta/\theta_{0}\right)
= \boldsymbol{X}\boldsymbol{\beta}
\]
\[
\text{Regularising fixed priors:} \qquad
\left.\boldsymbol{\beta} \right| I
\sim \mathrm{N}(0, 1)
\]

### Fitting a Stan model: Exponential likelihood with log link and regularising fixed priors

```{r stanExpRegFixed}
stanExpRegFixed <-
  rstan::stan(
    file = "expRegFixed.stan",
    data = dataList,
    chains = 4,
    iter = 2000,
    warmup = 1000,
    thin = 1,
    init = "random",
    algorithm = "NUTS",
    control = list(adapt_delta = 0.99,
                   max_treedepth = 15),
    cores = 3
  )
```

### HMC diagnostics

```{r diagnExpRegFixed}
rstan::check_hmc_diagnostics(object = stanExpRegFixed)
rstan::stan_trace(
  object = stanExpRegFixed,
  pars = c("beta", "lp__"),
  inc_warmup = TRUE
)
```

### Summary of posterior marginal probability distributions for model parameters

```{r summaryExpRegFixed}
print(
  x = stanExpRegFixed,
  pars = c("beta", "lp__"),
  probs = c(0.015, 0.25, 0.50, 0.75, 0.985)
)
rstan::stan_plot(
  object = stanExpRegFixed,
  pars = c("beta"),
  ci_level = 0.89,
  outer_level = 0.97
)
rstan::stan_dens(object = stanExpRegFixed,
                 pars = c("beta", "lp__"))
```

### Posterior predictive checks

```{r ppcExpRegFixed}
draws <-
  as.matrix(x = stanExpRegFixed,
            pars = "yrep")

bayesplot::ppc_dens_overlay(y = dataList$y,
                            yrep = draws[501:600,]) +
  ggplot2::labs(
    title = paste0(
      "Posterior predictive distribution ",
      "(re-using predictor data)"
    ),
    subtitle = "Empirical density overlaid with 100 HMC samples"
  ) +
  ggplot2::xlab(label = "y [min]") +
  ggplot2::ylab(label = "Density [1/min]") +
  ggplot2::theme_bw()

bayesplot::ppc_intervals(
  y = dataList$y,
  yrep = draws,
  prob = 0.89,
  prob_outer = 0.97,
  size = 1,
  fatten = 3
) +
  ggplot2::labs(
    title = paste0(
      "Posterior predictive compatibility intervals ",
      "(re-using predictor data)"
    ),
    subtitle = "Data points overlaid with interval estimates"
  ) +
  ggplot2::xlab(label = "Sample number") +
  ggplot2::ylab(label = "y [min]") +
  ggplot2::theme_bw()
```

### Remarks

clear data
```{r clearExpRegFixed}
rm(dataList, draws, stanExpRegFixed)
```

# Varying effects generalised linear models

## Multi-level linear regression

### Data, visualisation and research question

**data set** `iris` from R package `datasets` by the R Core Team (2022).

```{r dataLinRegNormVarying}
data("iris")
attach(what = iris)
any(is.na(x = iris)) # Checking for missing values in the data matrix
dat <-
  stats::na.omit(object = iris) %>% # Delete cases with missing values
  tibble::as_tibble(x = .) %>%
  dplyr::group_by(.data = ., Species) %>%
  dplyr::mutate(.data = ., gp = dplyr::cur_group_id()) %>% # Create group index
  dplyr::ungroup(x = .)
rm(iris)
dim(x = dat)
head(x = dat)
```

**visualisation** (variables `Sepal.Width` and `Petal.Length` suppressed)

```{r visLinRegNormVarying}
dat %>%
  ggplot2::ggplot(data = ., mapping = aes(x = Sepal.Length, y = Petal.Width)) +
  ggplot2::geom_point() +
  ggplot2::facet_wrap(facets = ~ Species) +
  ggplot2::scale_x_continuous(name = "Sepal length [cm]") +
  ggplot2::scale_y_continuous(name = "Petal width [cm]") +
  ggplot2::theme_bw()
```

**standardisation** of **variables**

`y`: standardised petal width [cm] (`Petal.Width`)

`x1`: standardised sepal length [cm] (`Sepal.Length`)

`x2`: standardised sepal width [cm] (`Sepal.Width`)

`x3`: standardised petal length [cm] (`Petal.Length`)

`gp`: group index: `1` (`setosa`), `2` (`versicolor`), `3` (`virginica`)

```{r standLinRegNormVarying}
Z <-
  scale(x = dat[, 1:4],
        center = TRUE,
        scale = TRUE) %>%
  magrittr::set_colnames(x = ., value = c("x1", "x2", "x3", "y")) %>%
  tibble::as_tibble(x = .)
head(x = Z)
```

**design matrix**

```{r designLinRegNormVarying}
X <-
  unname(stats::model.matrix(object = y ~ 1 + x1 + x2 + x3,
                             data = Z))
attr(x = X, which = "assign") <- NULL
head(x = X)
```

data list for Stan simulation

```{r listLinRegNormVarying}
dataList <-
  list(
    N = nrow(x = X),
    M = ncol(x = X),
    K = length(x = unique(x = dat$gp)),
    L = 1L,
    u = matrix(
      data = rep(1.0, length(x = unique(x = dat$gp))),
      nrow = length(x = unique(x = dat$gp)),
      ncol = 1L
    ),
    X = X,
    y = as.numeric(x = Z$y),
    gp = dat$gp
  )
rm(dat, X, Z)
```

### Statistical model

**model parameters** $\boldsymbol{\gamma}_{\boldsymbol{\beta}}[gp]$,
$\boldsymbol{\sigma}_{\boldsymbol{\beta}}[gp]$,
$\boldsymbol{L}_{\boldsymbol{R}_{\boldsymbol{\beta}}}$,
$\boldsymbol{z}_{\boldsymbol{\beta}}[gp]$ and $\sigma$.

\[
\text{Likelihood:}  \qquad
\left.\boldsymbol{y}\right| \boldsymbol{X}, \boldsymbol{\beta},
\sigma^{2}, [gp], I
\stackrel{\mathrm{ind}}{\sim} \mathrm{N}(
\boldsymbol{\mu}[gp], \sigma^{2}) \ ,
\qquad
\sigma^{2} := \mathrm{Var}\left(\left.\boldsymbol{y}\right| \boldsymbol{X}, \boldsymbol{\beta}, [gp], I\right) = \text{constant}
\]
\[
\text{Linear model:} \qquad
\boldsymbol{\mu}[gp] := \mathrm{E}\left(\left.\boldsymbol{y}\right| \boldsymbol{X}, 
\boldsymbol{\beta}, \sigma^{2}, [gp], I\right)
= \boldsymbol{X}[gp]\,\boldsymbol{\beta}[gp]
\]
\[
\text{Non-centred decomposition::} \qquad
\boldsymbol{\beta}[gp]
= \boldsymbol{u}\boldsymbol{\gamma}_{\boldsymbol{\beta}}[gp]
+ \text{diag}(\boldsymbol{\sigma}_{\boldsymbol{\beta}}[gp])\,
\boldsymbol{L}_{\boldsymbol{R}_{\boldsymbol{\beta}}}\,
\boldsymbol{z}_{\boldsymbol{\beta}}[gp]
\]
\[
\text{Regularising fixed priors:} \qquad
\left.\boldsymbol{\gamma}_{\boldsymbol{\beta}}[gp]
\right|\sigma^{2}, I
\sim \mathrm{N}(0, 1) \ ,
\qquad
\left.\boldsymbol{\sigma}_{\boldsymbol{\beta}}[gp]
\right|\sigma^{2}, I
\sim \mathrm{Exp}(1) \ ,
\qquad
\left.\boldsymbol{L}_{\boldsymbol{R}_{\boldsymbol{\beta}}}
\right|\sigma^{2}, I
\sim \mathrm{LKJ}(2) \ ,
\qquad
\left.\boldsymbol{z}_{\boldsymbol{\beta}}[gp]\right|\sigma^{2}, I
\sim \mathrm{N}(0, 1) \ ,
\qquad
\left.\sigma\right| I
\sim \mathrm{Exp}(1)
\]

### Fitting a Stan model: Gauß likelihood and adaptive priors (non-centred parametrisation)

```{r stanLinRegNormVarying}
stanLinRegNormVarying <-
  rstan::stan(
    file = "linRegNormVarying.stan",
    data = dataList,
    chains = 4,
    iter = 2000,
    warmup = 1000,
    thin = 1,
    init = "random",
    algorithm = "NUTS",
    control = list(adapt_delta = 0.99,
                   max_treedepth = 15),
    cores = 3
  )
```

See also the Stan User's Guide (Version 2.30), Sec. 1.13, URL (cited on
August 20, 2022): 
https://mc-stan.org/docs/stan-users-guide/multivariate-hierarchical-priors.html.

### HMC diagnostics

```{r diagnLinRegNormVarying}
rstan::check_hmc_diagnostics(object = stanLinRegNormVarying)
rstan::stan_trace(
  object = stanLinRegNormVarying,
  pars = c("beta", "R_beta", "sigma", "lp__"),
  inc_warmup = TRUE
)
```

### Summary of posterior marginal probability distributions for model parameters

**No** densities displayed for reasons of space.

```{r summaryLinRegNormVarying}
print(
  x = stanLinRegNormVarying,
  pars = c("beta", "R_beta", "sigma", "lp__"),
  probs = c(0.015, 0.25, 0.50, 0.75, 0.985)
)
rstan::stan_plot(
  object = stanLinRegNormVarying,
  pars = c("beta", "sigma"),
  ci_level = 0.89,
  outer_level = 0.97
)
rstan::stan_plot(
  object = stanLinRegNormVarying,
  pars = c("R_beta"),
  ci_level = 0.89,
  outer_level = 0.97
)
```

### Posterior predictive checks

```{r ppcLinRegNormVarying}
draws <-
  as.matrix(x = stanLinRegNormVarying,
            pars = "yrep")

bayesplot::ppc_dens_overlay(y = dataList$y,
                            yrep = draws[501:600, ]) +
  ggplot2::labs(
    title = paste0(
      "Posterior predictive distribution ",
      "(re-using predictor data)"
    ),
    subtitle = "Empirical density overlaid with 100 HMC samples"
  ) +
  ggplot2::xlab(label = "Standardised y [1]") +
  ggplot2::ylab(label = "Density [1]") +
  ggplot2::theme_bw()

bayesplot::ppc_intervals_grouped(
  y = dataList$y,
  yrep = draws,
  group = dataList$gp,
  prob = 0.89,
  prob_outer = 0.97,
  size = 1,
  fatten = 3
) +
  ggplot2::labs(
    title = paste0(
      "Posterior predictive compatibility intervals ",
      "(re-using predictor data)"
    ),
    subtitle = "Data points overlaid with interval estimates"
  ) +
  ggplot2::xlab(label = "Sample number") +
  ggplot2::ylab(label = "Standardised y [1]") +
  ggplot2::theme_bw()
```

### Pareto-smoothed importance-sampling leave-one-out cross-validation (PSIS-LOO)

```{r looLinRegNormVarying}
looLinRegNormVarying <-
  loo::loo(x = stanLinRegNormVarying,
           pars = "log_lik")
print(x = looLinRegNormVarying)
plot(x = looLinRegNormVarying,
     label_points = TRUE)
```

### Remarks

clear data
```{r clearLinRegNormVarying}
rm(dataList, draws, stanLinRegNormVarying, looLinRegNormVarying)
```

## Multi-level ANOVA-like regression

### Data, visualisation and research question

**data set** `massMonitoring.csv` and **variables**, as in Sec. ... above.

```{r dataAnovaRegNormVarying}
dat <-
  utils::read.csv(file = "massMonitoring.csv") %>%
  tibble::as_tibble(x = .)
any(is.na(x = dat))
dim(x = dat)
head(x = dat)
```

data list for Stan simulation

```{r listAnovaRegNormVarying}
dataList <-
  list(
    N = as.integer(x = nrow(x = dat)),
    K = length(x = unique(x = dat$X2)),
    gp = dat$X2,
    y = dat$X1
  )
rm(dat)
```

### Statistical model

**model parameters** $\boldsymbol{\mu}[gp]$ and $\boldsymbol{\sigma}[gp]$

\[
\text{Likelihood:}  \qquad
\left.\boldsymbol{y}\right| \boldsymbol{\mu},
\sigma^{2}, [gp], I
\stackrel{\mathrm{ind}}{\sim} \mathrm{N}(\boldsymbol{\mu}[gp],
\boldsymbol{\sigma}^{2}[gp])
\]
\[
\text{Adaptive priors:} \qquad
\boldsymbol{\mu}[gp]
\sim \mathrm{N}(\mu_{\mu}, \sigma_{\mu}^{2}) \ ,
\qquad
\boldsymbol{\sigma}[gp]
\sim \mathrm{Exp}(\beta_{\sigma})
\]
\[
\text{Weakly regularising fixed priors:} \qquad
\mu_{\mu}
\sim \mathrm{N}(90~\mathrm{kg}, (2~\mathrm{kg})^{2}) \ ,
\qquad
\sigma_{\mu}
\sim \mathrm{Exp}(1) \ ,
\qquad
\beta_{\sigma}
\sim \mathrm{Exp}(1)
\]

### Fitting a Stan model: Gauß likelihood, inhomogeneous variances and adaptive priors

```{r stanAnovaRegNormVarying}
stanAnovaRegNormVarying <-
  rstan::stan(
    file = "anovaRegNormVarying.stan",
    data = dataList,
    chains = 4,
    iter = 2000,
    warmup = 1000,
    thin = 1,
    init = "random",
    algorithm = "NUTS",
    control = list(adapt_delta = 0.99,
                   max_treedepth = 15),
    cores = 3
  )
```

### HMC diagnostics

```{r diagnAnovaRegNormVarying}
rstan::check_hmc_diagnostics(object = stanAnovaRegNormVarying)
rstan::stan_trace(
  object = stanAnovaRegNormVarying,
  pars = c("mu", "sigma", "lp__"),
  inc_warmup = TRUE
)
```

### Summary of posterior marginal probability distributions for model parameters

```{r summaryAnovaRegNormVarying}
print(
  x = stanAnovaRegNormVarying,
  pars = c("mu", "sigma", "lp__"),
  probs = c(0.015, 0.25, 0.50, 0.75, 0.985)
)
rstan::stan_plot(
  object = stanAnovaRegNormVarying,
  pars = c("mu"),
  ci_level = 0.89,
  outer_level = 0.97
)
rstan::stan_plot(
  object = stanAnovaRegNormVarying,
  pars = c("sigma"),
  ci_level = 0.89,
  outer_level = 0.97
)
rstan::stan_dens(object = stanAnovaRegNormVarying,
                 pars = c("mu", "sigma", "lp__"))
```

### Posterior predictive checks

```{r ppcAnovaRegNormVarying}
draws <-
  as.matrix(x = stanAnovaRegNormVarying,
            pars = "yrep")

bayesplot::ppc_dens_overlay(y = dataList$y,
                            yrep = draws[501:600,]) +
  ggplot2::labs(
    title = paste0(
      "Posterior predictive distribution ",
      "(re-using predictor data)"
    ),
    subtitle = "Empirical density overlaid with 100 HMC samples"
  ) +
  ggplot2::xlab(label = "y [kg]") +
  ggplot2::ylab(label = "Density [1/kg]") +
  ggplot2::theme_bw()

bayesplot::ppc_intervals_grouped(
  y = dataList$y,
  yrep = draws,
  group = dataList$gp,
  prob = 0.89,
  prob_outer = 0.97,
  size = 1,
  fatten = 3
) +
  ggplot2::labs(
    title = paste0(
      "Posterior predictive compatibility intervals ",
      "(re-using predictor data)"
    ),
    subtitle = "Data points overlaid with interval estimates"
  ) +
  ggplot2::xlab(label = "Sample number") +
  ggplot2::ylab(label = "y [kg]") +
  ggplot2::theme_bw()
```

### Pareto-smoothed importance-sampling leave-one-out cross-validation (PSIS-LOO)

```{r looAnovaRegNormVarying}
looAnovaRegNormVarying <-
  loo::loo(x = stanAnovaRegNormVarying,
           pars = "log_lik")
print(x = looAnovaRegNormVarying)
plot(x = looAnovaRegNormVarying,
     label_points = TRUE)
```

### Remarks

clear data
```{r clearAnovaRegNormVarying}
rm(dataList, draws, stanAnovaRegNormVarying, looLinRegNormVarying)
```

## Multi-level logistic regression

### Data, visualisation and research question

**data set** `bankloan.RData` (IBM SPSS tutorial binary logistic regression),
URL (cited on August 21, 2022):
https://www.ibm.com/support/knowledgecenter/en/SSLVMB_sub/statistics_casestudies_project_ddita/spss/tutorials/log_bankloan_intro.html.

```{r dataLogistRegBernVarying}
load("bankloan.RData")
attach(what = bankloan)
any(is.na(x = bankloan)) # Checking for missing values in the data matrix
dat <-
  stats::na.omit(object = bankloan) %>% # Delete cases with missing values
  tibble::as_tibble(x = .)
rm(bankloan)
dim(x = dat)
head(x = dat)
```

**standardisation** of **variables**

`y`: indicator of previous defaults: {0, 1} (`default`)

`x1`: standardised age [yr] (`age`)

`x2`: standardised years with current employer [yr] (`employ`)

`x3`: standardised years at current address [yr] (`address`)

`x4`: standardised household income [$ 10³] (`income`)

`x5`: standardised debt to income ratio [%] (`debtinc`)

`x6`: standardised credit card debt [$ 10³] (`creddebt`)

`x7`: standardised other debt [$ 10³] (`othdebt`)

`gp`: level of education: "did not complete high school" (`1`), "high school 
degree" (`2`), "some college" (`3`), "college degree" (`4`), "doctorate" (`5`) 
(`ed`)

```{r standLogistRegBernVarying}
Z <-
  scale(x = dat[, c(1, 3:8)],
        center = TRUE,
        scale = TRUE) %>%
  magrittr::set_colnames(x = .,
                         value = c("x1", "x2", "x3", "x4", "x5",
                                   "x6", "x7")) %>%
  tibble::as_tibble(x = .)
head(x = Z)
```

**design matrix**

```{r designLogistRegBernVarying}
X <-
  unname(stats::model.matrix(
    object = dat$default ~ 1 + x1 + x2 + x3 + x4 + x5 + x6 + x7,
    data = Z
  ))
attr(x = X, which = "assign") <- NULL
head(x = X)
```

data list for Stan simulation

```{r listLogistRegBernVarying}
dataList <-
  list(
    N = nrow(x = X),
    M = ncol(x = X),
    K = length(x = unique(x = dat$ed)),
    L = 1L,
    u = matrix(
      data = rep(1.0, length(x = unique(x = dat$ed))),
      nrow = length(x = unique(x = dat$ed)),
      ncol = 1L
    ),
    X = X,
    y = as.integer(x = dat$default),
    gp = as.integer(x = dat$ed)
  )
rm(dat, X, Z)
```

### Statistical model

**model parameters** $\boldsymbol{\gamma}_{\boldsymbol{\beta}}[gp]$,
$\boldsymbol{\sigma}_{\boldsymbol{\beta}}[gp]$,
$\boldsymbol{L}_{\boldsymbol{R}_{\boldsymbol{\beta}}}$ and
$\boldsymbol{z}_{\boldsymbol{\beta}}[gp]$.

\[
\text{Likelihood:}  \qquad
\left.\boldsymbol{y}\right| \boldsymbol{X}, \boldsymbol{\beta}, [gp], I
\stackrel{\mathrm{ind}}{\sim} \mathrm{Bern}(p[gp])
\]
\[
\text{Linear model:} \qquad
\text{logit}(p)[gp] :=
\ln\left(\frac{p}{1-p}\right)[gp]
= \boldsymbol{X}[gp]\,\boldsymbol{\beta}[gp]
\]
\[
\text{Non-centred decomposition::} \qquad
\boldsymbol{\beta}[gp]
= \boldsymbol{u}\boldsymbol{\gamma}_{\boldsymbol{\beta}}[gp]
+ \text{diag}(\boldsymbol{\sigma}_{\boldsymbol{\beta}}[gp])\,
\boldsymbol{L}_{\boldsymbol{R}_{\boldsymbol{\beta}}}\,
\boldsymbol{z}_{\boldsymbol{\beta}}[gp]
\]
\[
\text{Regularising fixed priors:} \qquad
\left.\boldsymbol{\gamma}_{\boldsymbol{\beta}}[gp]\right| I
\sim \mathrm{N}(0, 1) \ ,
\qquad
\left.\boldsymbol{\sigma}_{\boldsymbol{\beta}}[gp]\right| I
\sim \mathrm{Exp}(1) \ ,
\qquad
\left.\boldsymbol{L}_{\boldsymbol{R}_{\boldsymbol{\beta}}}\right| I
\sim \mathrm{LKJ}(2) \ ,
\qquad
\left.\boldsymbol{z}_{\boldsymbol{\beta}}[gp]\right| I
\sim \mathrm{N}(0, 1)
\]

### Fitting a Stan model: Bernoulli likelihood with logit link and adaptive priors (non-centred parametrisation)

```{r stanLogistRegBernVarying}
stanLogistRegBernVarying <-
  rstan::stan(
    file = "logistRegBernVarying.stan",
    data = dataList,
    chains = 4,
    iter = 2000,
    warmup = 1000,
    thin = 1,
    init = "random",
    algorithm = "NUTS",
    control = list(adapt_delta = 0.99,
                   max_treedepth = 15),
    cores = 3
  )
```

See also the Stan User's Guide (Version 2.30), Secs. 1.9 and 1.13, URLs (cited
on August 21, 2022): 
https://mc-stan.org/docs/stan-users-guide/hierarchical-logistic-regression.html,
https://mc-stan.org/docs/stan-users-guide/multivariate-hierarchical-priors.html.

### HMC diagnostics

```{r diagnLogistRegBernVarying}
rstan::check_hmc_diagnostics(object = stanLogistRegBernVarying)
rstan::stan_trace(
  object = stanLogistRegBernVarying,
  pars = c("beta", "lp__"),
  inc_warmup = TRUE
)
```

### Summary of posterior marginal probability distributions for model parameters

**No** densities displayed for reasons of space.

```{r summaryLogistRegBernVarying}
print(
  x = stanLogistRegBernVarying,
  pars = c("beta", "lp__"),
  probs = c(0.015, 0.25, 0.50, 0.75, 0.985)
)
rstan::stan_plot(
  object = stanLogistRegBernVarying,
  pars = c("beta"),
  ci_level = 0.89,
  outer_level = 0.97
)
```

### Posterior predictive checks

```{r ppcLogistRegBernVarying}
draws <-
  as.matrix(x = stanLogistRegBernVarying,
            pars = "yrep")

bayesplot::ppc_dens_overlay(y = dataList$y,
                            yrep = draws[501:600,]) +
  ggplot2::labs(
    title = paste0(
      "Posterior predictive distribution ",
      "(re-using predictor data)"
    ),
    subtitle = "Empirical density overlaid with 100 HMC samples"
  ) +
  ggplot2::xlab(label = "y [1]") +
  ggplot2::ylab(label = "Density [1]") +
  ggplot2::theme_bw()

bayesplot::ppc_intervals_grouped(
  y = dataList$y,
  yrep = draws,
  group = dataList$gp,
  prob = 0.89,
  prob_outer = 0.97,
  size = 1,
  fatten = 3
) +
  ggplot2::labs(
    title = paste0(
      "Posterior predictive compatibility intervals ",
      "(re-using predictor data)"
    ),
    subtitle = "Data points overlaid with interval estimates"
  ) +
  ggplot2::xlab(label = "Sample number") +
  ggplot2::ylab(label = "y [1]") +
  ggplot2::theme_bw()
```

### Pareto-smoothed importance-sampling leave-one-out cross-validation (PSIS-LOO)

```{r looLogistRegBernVarying}
looLogistRegBernVarying <-
  loo::loo(x = stanLogistRegBernVarying,
           pars = "log_lik")
print(x = looLogistRegBernVarying)
plot(x = looLogistRegBernVarying,
     label_points = TRUE)
```

### Remarks

clear data
```{r clearLogistRegBernVarying}
rm(dataList, draws, stanLogistRegBernVarying, looLogistRegBernVarying)
```

## Multi-level Poisson regression

### Data, visualisation and research question

**data set** `poissonData.RData` and **variables**, as in Sec. ... above.

```{r dataPoisRegVarying}
load("poissonData.RData")
attach(what = poissonData)
any(is.na(x = poissonData)) # Checking for missing values in the data matrix
dat <-
  stats::na.omit(object = poissonData) %>% # Delete cases with missing values
  tibble::as_tibble(x = .)
rm(poissonData)
dim(x = dat)
head(x = dat)
```

```{r standPoisRegVarying}
Z <-
  scale(x = dat[, 2:4],
        center = TRUE,
        scale = TRUE) %>%
  magrittr::set_colnames(x = ., value = c("x1", "x2", "x3")) %>%
  tibble::as_tibble(x = .)
head(x = Z)
```

**design matrix**

```{r designPoisRegVarying}
X <-
  unname(stats::model.matrix(object = dat$y ~ 1 + x1 + x2 + x3,
                             data = Z))
attr(x = X, which = "assign") <- NULL
head(x = X)
```

data list for Stan simulation

```{r listPoisRegVarying}
dataList <-
  list(
    N = nrow(x = X),
    M = ncol(x = X),
    K = length(x = unique(x = dat$gp)),
    L = 1L,
    u = matrix(
      data = rep(1.0, length(x = unique(x = dat$gp))),
      nrow = length(x = unique(x = dat$gp)),
      ncol = 1L
    ),
    X = X,
    y = as.integer(x = dat$y),
    gp = as.integer(x = dat$gp)
  )
rm(dat, X, Z)
```

### Statistical model

**model parameters** $\boldsymbol{\gamma}_{\boldsymbol{\beta}}[gp]$,
$\boldsymbol{\sigma}_{\boldsymbol{\beta}}[gp]$,
$\boldsymbol{L}_{\boldsymbol{R}_{\boldsymbol{\beta}}}$ and
$\boldsymbol{z}_{\boldsymbol{\beta}}[gp]$.

\[
\text{Likelihood:}  \qquad
\left.\boldsymbol{y}\right| \boldsymbol{X}, \boldsymbol{\beta}, [gp], I
\stackrel{\mathrm{ind}}{\sim} \mathrm{Pois}(\theta[gp])
\]
\[
\text{Linear model:} \qquad
\ln\left(\theta\right)[gp]
= \boldsymbol{X}[gp]\,\boldsymbol{\beta}[gp]
\]
\[
\text{Non-centred decomposition::} \qquad
\boldsymbol{\beta}[gp]
= \boldsymbol{u}\boldsymbol{\gamma}_{\boldsymbol{\beta}}[gp]
+ \text{diag}(\boldsymbol{\sigma}_{\boldsymbol{\beta}}[gp])\,
\boldsymbol{L}_{\boldsymbol{R}_{\boldsymbol{\beta}}}\,
\boldsymbol{z}_{\boldsymbol{\beta}}[gp]
\]
\[
\text{Regularising fixed priors:} \qquad
\left.\boldsymbol{\gamma}_{\boldsymbol{\beta}}[gp]\right| I
\sim \mathrm{N}(0, 1) \ ,
\qquad
\left.\boldsymbol{\sigma}_{\boldsymbol{\beta}}[gp]\right| I
\sim \mathrm{Exp}(1) \ ,
\qquad
\left.\boldsymbol{L}_{\boldsymbol{R}_{\boldsymbol{\beta}}}\right| I
\sim \mathrm{LKJ}(2) \ ,
\qquad
\left.\boldsymbol{z}_{\boldsymbol{\beta}}[gp]\right| I
\sim \mathrm{N}(0, 1)
\]

### Fitting a Stan model: Poisson likelihood with log link and adaptive priors (non-centred parametrisation)

```{r stanPoisRegVarying}
stanPoisRegVarying <-
  rstan::stan(
    file = "poisRegVarying.stan",
    data = dataList,
    chains = 4,
    iter = 2000,
    warmup = 1000,
    thin = 1,
    init = "random",
    algorithm = "NUTS",
    control = list(adapt_delta = 0.99,
                   max_treedepth = 15),
    cores = 3
  )
```

### HMC diagnostics

```{r diagnPoisRegVarying}
rstan::check_hmc_diagnostics(object = stanPoisRegVarying)
rstan::stan_trace(
  object = stanPoisRegVarying,
  pars = c("beta", "lp__"),
  inc_warmup = TRUE
)
```

### Summary of posterior marginal probability distributions for model parameters

**No** densities displayed for reasons of space.

```{r summaryPoisRegVarying}
print(
  x = stanPoisRegVarying,
  pars = c("beta", "lp__"),
  probs = c(0.015, 0.25, 0.50, 0.75, 0.985)
)
rstan::stan_plot(
  object = stanPoisRegVarying,
  pars = c("beta"),
  ci_level = 0.89,
  outer_level = 0.97
)
```

### Posterior predictive checks

```{r ppcPoisRegVarying}
draws <-
  as.matrix(x = stanPoisRegVarying,
            pars = "yrep")

bayesplot::ppc_dens_overlay(y = dataList$y,
                            yrep = draws[501:600,]) +
  ggplot2::labs(
    title = paste0(
      "Posterior predictive distribution ",
      "(re-using predictor data)"
    ),
    subtitle = "Empirical density overlaid with 100 HMC samples"
  ) +
  ggplot2::ylab(label = "Density [1]") +
  ggplot2::scale_x_continuous(
    name = "y [1]",
    breaks = seq(from = 0, to = 8, by = 1),
    labels = scales::number_format(
      accuracy = 1,
      big.mark = ".",
      decimal.mark = ","
    )
  ) +
  ggplot2::theme_bw()

bayesplot::ppc_intervals_grouped(
  y = dataList$y,
  yrep = draws,
  group = dataList$g ,
  prob = 0.89,
  prob_outer = 0.97,
  size = 1,
  fatten = 3
) +
  ggplot2::labs(
    title = paste0(
      "Posterior predictive compatibility intervals ",
      "(re-using predictor data)"
    ),
    subtitle = "Data points overlaid with interval estimates"
  ) +
  ggplot2::xlab(label = "Sample number") +
  ggplot2::ylab(label = "y [1]") +
  ggplot2::theme_bw()
```

### Pareto-smoothed importance-sampling leave-one-out cross-validation (PSIS-LOO)

```{r looPoisRegVarying}
looPoisRegVarying <-
  loo::loo(x = stanPoisRegVarying,
           pars = "log_lik")
print(x = looPoisRegVarying)
plot(x = looPoisRegVarying,
     label_points = TRUE)
```

### Remarks

clear data
```{r clearPoisRegVarying}
rm(dataList, draws, stanPoisRegVarying, looPoisRegVarying)
```

## Multi-level exponential regression

### Data, visualisation and research question

**data set** `tramWait.RData` and **variables**, as in Sec. ... above.

```{r dataExpRegVarying}
load("tramWait.RData")
attach(what = tramWait)
any(is.na(x = tramWait)) # Checking for missing values in the data matrix
dat <-
  stats::na.omit(object = tramWait) %>%  # Delete cases with missing values
  tibble::as_tibble(x = .)
rm(tramWait)
dim(x = dat)
head(x = dat)
```

**visualisation** (variable `conductors` suppressed)

```{r visExpRegVarying}
dat %>%
  ggplot2::ggplot(data = ., mapping = aes(x = passChanged, y = wait)) +
  ggplot2::geom_point() +
  ggplot2::facet_wrap(facets = ~ tram) +
  ggplot2::scale_x_continuous(name = "No. of passengers changing [1]") +
  ggplot2::scale_y_continuous(name = "Waiting time [min]") +
  ggplot2::theme_bw()
```

**standardisation** of data

```{r standExpRegVarying}
Z <-
  scale(x = dat[, 2:3],
        center = TRUE,
        scale = TRUE) %>%
  magrittr::set_colnames(x = ., value = c("x1", "x2")) %>%
  tibble::as_tibble(x = .)
head(x = Z)
```

**design matrix**

```{r designExpRegVarying}
X <-
  unname(stats::model.matrix(object = dat$wait ~ 1 + x1 + x2,
                             data = Z))
attr(x = X, which = "assign") <- NULL
head(x = X)
```

data list for Stan simulation

```{r listExpRegVarying}
dataList <-
  list(
    N = nrow(x = X),
    M = ncol(x = X),
    K = length(x = unique(x = dat$tram)),
    L = 1L,
    u = matrix(
      data = rep(1.0, length(x = unique(x = dat$tram))),
      nrow = length(x = unique(x = dat$tram)),
      ncol = 1L
    ),
    X = X,
    y = dat$wait,
    gp = dat$tram
  )
rm(dat, X, Z)
```

### Statistical model

**model parameters** $\boldsymbol{\gamma}_{\boldsymbol{\beta}}[gp]$,
$\boldsymbol{\sigma}_{\boldsymbol{\beta}}[gp]$,
$\boldsymbol{L}_{\boldsymbol{R}_{\boldsymbol{\beta}}}$ and
$\boldsymbol{z}_{\boldsymbol{\beta}}[gp]$.

\[
\text{Likelihood:}  \qquad
\left.\boldsymbol{y}\right| \boldsymbol{X}, \boldsymbol{\beta}, [gp], I
\stackrel{\mathrm{ind}}{\sim} \mathrm{Exp}(\theta[gp])
\]
\[
\text{Linear model:} \qquad
\ln\left(\theta/\theta_{0}\right)[gp]
= \boldsymbol{X}[gp]\,\boldsymbol{\beta}[gp]
\]
\[
\text{Non-centred decomposition::} \qquad
\boldsymbol{\beta}[gp]
= \boldsymbol{u}\boldsymbol{\gamma}_{\boldsymbol{\beta}}[gp]
+ \text{diag}(\boldsymbol{\sigma}_{\boldsymbol{\beta}}[gp])\,
\boldsymbol{L}_{\boldsymbol{R}_{\boldsymbol{\beta}}}\,
\boldsymbol{z}_{\boldsymbol{\beta}}[gp]
\]
\[
\text{Regularising fixed priors:} \qquad
\left.\boldsymbol{\gamma}_{\boldsymbol{\beta}}[gp]\right| I
\sim \mathrm{N}(0, 1) \ ,
\qquad
\left.\boldsymbol{\sigma}_{\boldsymbol{\beta}}[gp]\right| I
\sim \mathrm{Exp}(1) \ ,
\qquad
\left.\boldsymbol{L}_{\boldsymbol{R}_{\boldsymbol{\beta}}}\right| I
\sim \mathrm{LKJ}(2) \ ,
\qquad
\left.\boldsymbol{z}_{\boldsymbol{\beta}}[gp]\right| I
\sim \mathrm{N}(0, 1)
\]

### Fitting a Stan model: Exponential likelihood with log link and adaptive priors (non-centred parametrisation)

```{r stanExpRegVarying}
stanExpRegVarying <-
  rstan::stan(
    file = "expRegVarying.stan",
    data = dataList,
    chains = 4,
    iter = 2000,
    warmup = 1000,
    thin = 1,
    init = "random",
    algorithm = "NUTS",
    control = list(adapt_delta = 0.99,
                   max_treedepth = 15),
    cores = 3
  )
```

### HMC diagnostics

```{r diagnExpRegVarying}
rstan::check_hmc_diagnostics(object = stanExpRegVarying)
rstan::stan_trace(
  object = stanExpRegVarying,
  pars = c("beta", "lp__"),
  inc_warmup = TRUE
)
```

### Summary of posterior marginal probability distributions for model parameters

**No** densities displayed for reasons of space.

```{r summaryExpRegVarying}
print(
  x = stanExpRegVarying,
  pars = c("beta", "lp__"),
  probs = c(0.015, 0.25, 0.50, 0.75, 0.985)
)
rstan::stan_plot(
  object = stanExpRegVarying,
  pars = c("beta"),
  ci_level = 0.89,
  outer_level = 0.97
)
```

### Posterior predictive checks

```{r ppcExpRegVarying}
draws <-
  as.matrix(x = stanExpRegVarying,
            pars = "yrep")

bayesplot::ppc_dens_overlay(y = dataList$y,
                            yrep = draws[501:600,]) +
  ggplot2::labs(
    title = paste0(
      "Posterior predictive distribution ",
      "(re-using predictor data)"
    ),
    subtitle = "Empirical density overlaid with 100 HMC samples"
  ) +
  ggplot2::xlab(label = "y [min]") +
  ggplot2::ylab(label = "Density [1/min]") +
  ggplot2::theme_bw()

bayesplot::ppc_intervals_grouped(
  y = dataList$y,
  yrep = draws,
  group = dataList$gp,
  prob = 0.89,
  prob_outer = 0.97,
  size = 1,
  fatten = 3
) +
  ggplot2::labs(
    title = paste0(
      "Posterior predictive compatibility intervals ",
      "(re-using predictor data)"
    ),
    subtitle = "Data points overlaid with interval estimates"
  ) +
  ggplot2::xlab(label = "Sample number") +
  ggplot2::ylab(label = "y [min]") +
  ggplot2::theme_bw()
```

### Pareto-smoothed importance-sampling leave-one-out cross-validation (PSIS-LOO)

```{r looExpRegVarying}
looExpRegVarying <-
  loo::loo(x = stanExpRegVarying,
           pars = "log_lik")
print(x = looExpRegVarying)
plot(x = looExpRegVarying,
     label_points = TRUE)
```

### Remarks

clear data
```{r clearExpRegVarying}
rm(dataList, draws, stanExpRegVarying, looExpRegVarying)
```

# Time series analysis

## Stationary linear $\text{AR}(p)$-model with Gauß likelihood

blog entry by Daniel Foley, dated Nov 10, 2018, on
"A Bayesian approach to time series forecasting", URL (cited on August 27,
2022): https://towardsdatascience.com/a-bayesian-approach-to-time-series-forecasting-d97dd4168cb7

### Data, visualisation and research question

**data set** `USGDPpcData.RData`, US GDP growth data from the Federal Reserve
of St. Louis website at the URL (cited on August 27, 2022): 
https://fred.stlouisfed.org/series/GDPC1#0;

```{r dataAR_p_NormFixed}
load("USGDPpc.RData")
attach(what = USGDPpc)
any(is.na(x = USGDPpc)) # Checking for missing values in the data matrix
dat <-
  stats::na.omit(object = USGDPpc) %>% # Delete cases with missing values
  tibble::as_tibble(x = .) %>%
  dplyr::filter(.data = ., date >= lubridate::ymd("1994-01-01"))
dat$date <-
  lubridate::as_datetime(x = dat$date)
rm(USGDPpc)
dim(x = dat)
head(x = dat)
```

**variables**

`T`: date of observation (`date`)

`y`: quarterly percentage change of US GDP [1] (`percentage_change`)

Prsent consideration restricted to the observations from the period
`1994-01-01` to `2018-10-01`.

**visualisation**

```{r visAP_p_NormFixed}
dat %>%
  ggplot2::ggplot(data = ., mapping = aes(x = date, y = percentage_change)) +
  ggplot2::geom_line() +
  ggplot2::scale_x_datetime(name = "Date of observation",
                            date_labels = "%b %Y") +
  ggplot2::scale_y_continuous(name = "Quarterly percentage change [%]") +
  ggplot2::theme_bw()
```

data list for Stan simulation

```{r listAR_p_NormFixed}
dataList <-
  list(T = as.integer(x = nrow(x = dat)),   # no. of time steps
       y = dat$percentage_change,           # times series data
       P = 2L)                              # order p of AR(p) model
rm(dat)
```

### Statistical model

**model parameters** $\alpha$, $\beta_{i}$ and $\sigma^{2}$, with the constraint 
$-1 < \beta_{i} < 1$ imposed in order to ensure a necessary (though not 
sufficient) condition for stationarity to hold for the time series model to be
constructed.

\[
\text{Likelihood:} \quad \left.y_{n}\right|y_{n-i}, \alpha,
\beta_{i}, \sigma^{2}, I
\stackrel{\mathrm{ind}}{\sim} \mathrm{N}\left(\mu_{n}, \sigma^{2}\right) \ ,
\qquad
\sigma_{n}^{2}
:= \mathrm{Var}\left(\left.y_{n}\right|y_{n-i}, \alpha, \beta_{i}, I\right)
= \text{constant}
\]
\[
\text{Linear model:} \quad \mu_{n}
:= \mathrm{E}\left(\left.y_{n}\right|y_{n-i}, \alpha,
\beta_{i}, \sigma^{2}, I\right)
= \alpha + \sum_{i=1}^{p}\beta_{i}y_{n-i}
\]
\[
\text{Regularising fixed priors:} \quad
\alpha, \beta_{i} \sim \mathrm{N}\left(0, 1\right) \ , \qquad
\sigma \sim \mathrm{Exp}(1)
\]

### Fitting a Stan model: Gauß likelihood with fixed priors

```{r stanAR_p_NormFixed}
stanAR_p_NormFixed <-
  rstan::stan(
    file = "AR_p_NormFixed.stan",
    data = dataList,
    chains = 4,
    iter = 2000,
    warmup = 1000,
    thin = 1,
    init = "random",
    algorithm = "NUTS",
    control = list(adapt_delta = 0.99,
                   max_treedepth = 15),
    cores = 3
  )
```

See also the Stan User's Guide (Version 2.30), Sec. 2.1, URL (cited on
August 27, 2022):
https://mc-stan.org/docs/stan-users-guide/autoregressive.html, and
Ali (2017), URL (cited on August 27, 2022):
https://imadali.net/projects/bsss/rstan/generated-quantities/.

### HMC diagnostics

```{r diagnAP_p_NormFixed}
rstan::check_hmc_diagnostics(object = stanAR_p_NormFixed)
rstan::stan_trace(
  object = stanAR_p_NormFixed,
  pars = c("alpha", "beta", "sigma", "lp__"),
  inc_warmup = TRUE
)
```

### Summary of posterior marginal probability distributions for model parameters

```{r summaryAP_p_NormFixed}
print(
  x = stanAR_p_NormFixed,
  pars = c("alpha", "beta", "sigma", "lp__"),
  probs = c(0.015, 0.25, 0.50, 0.75, 0.985)
)
rstan::stan_plot(
  object = stanAR_p_NormFixed,
  pars = c("alpha", "beta", "sigma"),
  ci_level = 0.89,
  outer_level = 0.97
)
rstan::stan_dens(object = stanAR_p_NormFixed,
                 pars = c("alpha", "beta", "sigma", "lp__"))
```

### Posterior predictive checks

```{r ppcAR_p_NormFixed}
draws <-
  as.matrix(x = stanAR_p_NormFixed,
            pars = "yrep")

bayesplot::ppc_dens_overlay(y = dataList$y[-c(1:2)],
                            yrep = draws[501:600,]) +
  ggplot2::labs(
    title = paste0(
      "Posterior predictive distribution ",
      "(re-using predictor data)"
    ),
    subtitle = "Empirical density overlaid with 100 HMC samples"
  ) +
  ggplot2::xlab(label = "Quarterly percentage change [%]") +
  ggplot2::ylab(label = "Density [1/%]") +
  ggplot2::theme_bw()

bayesplot::ppc_intervals(
  y = dataList$y[-c(1:2)],
  yrep = draws,
  prob = 0.89,
  prob_outer = 0.97,
  size = 1,
  fatten = 3
) +
  ggplot2::labs(
    title = paste0(
      "Posterior predictive compatibility intervals ",
      "(re-using predictor data)"
    ),
    subtitle = "Data points overlaid with interval estimates"
  ) +
  ggplot2::xlab(label = "Sample number") +
  ggplot2::ylab(label = "Quarterly percentage change [%]") +
  ggplot2::theme_bw()
```

### Remarks

clear data
```{r clearAR_p_NormFixed}
rm(dataList, draws, stanAR_p_NormFixed)
```

## Stationary linear $\text{GARCH}(1,1)$-model with Gauß likelihood

Bollerslev (1986), Bürkner *et al* (2020), approximating exact LFO-CV.

### Data, visualisation and research question

**data set** `massChangeData.RData`, **variables**

```{r dataGARCH_1_1_NormFixed}
load("massChangeData.RData")
attach(what = massChangeData)
any(is.na(x = massChangeData)) # Checking for missing values in the data matrix
dat <-
  stats::na.omit(object = massChangeData) %>% # Delete cases with missing 
                                              #   values
  tibble::as_tibble(x = .)
rm(massChangeData)
dim(x = dat)
head(x = dat)
```

**variables**

`T`: date of observation (`date`)

`y`: mass change [kg] (`massChange`)

observations from the period `2015-01-01` to
`2016-12-31`.

**visualisation**

```{r visGARCH_1_1_NormFixed}
dat %>%
  ggplot2::ggplot(data = ., mapping = aes(x = date, y = massChange)) +
  ggplot2::geom_line() +
  ggplot2::scale_x_datetime(name = "Date of observation",
                            date_labels = "%b %Y") +
  ggplot2::scale_y_continuous(name = "Mass change [kg]") +
  ggplot2::theme_bw()
```

data list for Stan simulation

```{r listGARCH_1_1_NormFixed}
dataList <-
  list(T = as.integer(x = nrow(x = dat)),   # no. of time steps
       y = dat$massChange,                  # times series data
       sigma1 = 2.0)                        # initial sd
rm(dat)
```

### Statistical model

**model parameters** $\mu$, $\alpha_{0} > 0$ and
$0 < \alpha_{1}, \beta_{1} < 1$, with the constraint $\alpha_{1} + \beta_{1}
< 1$ imposed in order to ensure stationarity.

\[
\text{Likelihood:} \quad \left.y_{n}\right|y_{n-1}, \mu, \alpha_{0},
\alpha_{1}, \beta_{1}, \sigma_{n-1}^{2}, I
\stackrel{\mathrm{ind}}{\sim} \mathrm{N}\left(\mu, \sigma_{n}^{2}\right) \ ,
\qquad
\mu := \mathrm{E}\left(\left.y_{n}\right|I\right)
= \text{constant}
\]
\[
\text{Linear model:} \quad \sigma_{n}^{2}
:= \mathrm{Var}\left(\left.y_{n}\right|y_{n-1}, \mu, \alpha_{0},
\alpha_{1}, \beta_{1}, \sigma_{n-1}^{2}, I\right)
= \alpha_{0} + \alpha_{1}\left(y_{n-1}-\mu\right)^{2}
+ \beta_{1}\sigma_{n-1}^{2}
\]
\[
\text{Fixed priors:} \quad
\mu \sim \mathrm{N}\left(0~\mathrm{kg}, (1,5~\mathrm{kg})^{2}\right) \ , \qquad
\alpha_{0} \sim \mathrm{Exp}(1) \ , \qquad
\alpha_{1}, \beta_{1} \sim \mathrm{Be}(1,1)
\]

### Fitting a Stan model: Gauß likelihood with fixed priors

```{r stanGARCH_1_1_NormFixed}
stanGARCH_1_1_NormFixed <-
  rstan::stan(
    file = "GARCH_1_1_NormFixed.stan",
    data = dataList,
    chains = 4,
    iter = 2000,
    warmup = 1000,
    thin = 1,
    init = "random",
    algorithm = "NUTS",
    control = list(adapt_delta = 0.99,
                   max_treedepth = 15),
    cores = 3
  )
```

See also the Stan User's Guide (Version 2.30), Sec. 2.2, URL (cited on
August 22, 2022): 
https://mc-stan.org/docs/stan-users-guide/modeling-temporal-heteroscedasticity.html.

### HMC diagnostics

```{r diagnGARCH_1_1_NormFixed}
rstan::check_hmc_diagnostics(object = stanGARCH_1_1_NormFixed)
rstan::stan_trace(
  object = stanGARCH_1_1_NormFixed,
  pars = c("mu", "alpha0", "alpha1", "beta1", "lp__"),
  inc_warmup = TRUE
)
```

### Summary of posterior marginal probability distributions for model parameters

```{r summaryGARCH_1_1_NormFixed}
print(
  x = stanGARCH_1_1_NormFixed,
  pars = c("mu", "alpha0", "alpha1", "beta1", "lp__"),
  probs = c(0.015, 0.25, 0.50, 0.75, 0.985)
)
rstan::stan_plot(
  object = stanGARCH_1_1_NormFixed,
  pars = c("mu", "alpha0", "alpha1", "beta1"),
  ci_level = 0.89,
  outer_level = 0.97
)
rstan::stan_dens(object = stanGARCH_1_1_NormFixed,
                 pars = c("mu", "alpha0", "alpha1", "beta1", "lp__"))
```

### Posterior predictive checks

```{r ppcGARCH_1_1_NormFixed}
draws <-
  as.matrix(x = stanGARCH_1_1_NormFixed,
            pars = "yrep")

bayesplot::ppc_dens_overlay(y = dataList$y,
                            yrep = draws[501:600,]) +
  ggplot2::labs(
    title = paste0(
      "Posterior predictive distribution ",
      "(re-using predictor data)"
    ),
    subtitle = "Empirical density overlaid with 100 HMC samples"
  ) +
  ggplot2::xlab(label = "Mass change [kg]") +
  ggplot2::ylab(label = "Density [1/kg]") +
  ggplot2::theme_bw()

bayesplot::ppc_intervals(
  y = dataList$y,
  yrep = draws,
  prob = 0.89,
  prob_outer = 0.97,
  size = 1,
  fatten = 3
) +
  ggplot2::labs(
    title = paste0(
      "Posterior predictive compatibility intervals ",
      "(re-using predictor data)"
    ),
    subtitle = "Data points overlaid with interval estimates"
  ) +
  ggplot2::xlab(label = "Sample number") +
  ggplot2::ylab(label = "Mass change [kg]") +
  ggplot2::theme_bw()
```

### Remarks

clear data
```{r clearGARCH_1_1_NormFixed}
rm(dataList, draws, stanGARCH_1_1_NormFixed)
```

# References

1. S Bache and H Wickham (2022) magrittr: A forward-pipe operator for R (R package version 2.0.3) URL (cited on August 18, 2022): https://CRAN.R-project.org/package=magrittr

2. T Bollerslev (1986) Generalized autoregressive conditional heteroskedasticity *Journal of Econometrics* **31** 307-327 DOI: https://doi.org/10.1016/0304-4076(86)90063-1

3. P-C Bürkner, J Gabry and A Vehtari (2020) Approximate leave-future-out cross-validation for Bayesian time series models *Journal of Statistical Computation and Simulation* **90** 2499–2523 DOI: https://doi.org/10.1080/00949655.2020.1783262

4. A Canty and B Ripley (2021) boot: Bootstrap R (S-Plus) functions (R package version 1.3-28) URL (cited on August 18, 2022): https://CRAN.R-project.org/package=boot

5. B Carpenter, A Gelman, M D Hoffman, D Lee, B Goodrich, M Betancourt, M Brubaker, J Guo, P Li and A Riddell (2017) Stan: A probabilistic programming language *Journal of Statistical Software* **76** 1–32 DOI: https://doi.org/10.18637/jss.v076.i01

6. H van Elst (2022) An introduction to inductive statistical inference: from parameter estimation to decision-making *eprint* arXiv:1808.10173v3 [stat.AP] URL: https://arxiv.org/abs/1808.10173 [See also URL: https://www.researchgate.net/publication/327336588_An_Introduction_to_Inductive_Statistical_Inference_from_Parameter_Estimation_to_Decision-Making_version_3]

7. J Gabry, Daniel Simpson, A Vehtari, M Betancourt and A Gelman (2019) Visualization in Bayesian workflow *Journal of the Royal Statistical Society: Series A (Statistics in Society)* **182** 389-402 DOI: https://doi.org/10.1111/rssa.12378 [arXiv: https://arxiv.org/abs/1709.01449]

8. J Gabry and T Mahr (2022) bayesplot: Plotting for Bayesian models (R package version 1.9.0) URL (cited on August 18, 2022): https://CRAN.R-project.org/package=bayesplot

9. A Gelman, J B Carlin, H S Stern, D B Dunson, A Vehtari and D B Rubin (2014) *Bayesian Data Analysis* 3rd Edition (Boca Raton, FL: Chapman & Hall) ISBN–13: 9781439840955

10. G Grolemund and Hadley Wickham (2011) Dates and times made easy with lubridate *Journal of Statistical Software* **40**(3) 1-25 URL: https://www.jstatsoft.org/v40/i03/

11. D Kahneman (2011) Thinking, Fast and Slow (London: Penguin) ISBN–13: 9780141033570

12. R McElreath (2020) *Statistical Rethinking — A Bayesian Course with Examples in R and Stan* 2nd Edition (Boca Raton, FL: Chapman & Hall) ISBN–13: 9780367139919

13. R Core Team (2022) R: A language and environment for statistical computing (Wien: R Foundation for Statistical Computing) URL (cited on August 18, 2022): https://www.R-project.org

14. B Schloerke, D Cook, J Larmarange, F Briatte, M Marbach, E Thoen, A Elberg and J Crowley (2021) GGally: Extension to 'ggplot2' (R package version 2.1.2) URL (cited on August 21,  2022): https://CRAN.R-project.org/package=GGally

15. Stan Development Team (2022a) *Stan* URL (cited on August 18, 2022): https://mc-stan.org

16. Stan Development Team (2022b) rstan: R interface to Stan (R package version 2.21.5) URL (cited on August 17, 2022): https://CRAN.R-project.org/package=rstan

17. A Vehtari, J Gabry, M Magnusson, Y Yao, P Bürkner, T Paananen and A Gelman (2022) loo: Efficient leave-one-out cross-validation and WAIC for Bayesian models (R package version 2.5.1) URL (cited on August 20, 2022): https://mc-stan.org/loo/

18. H Wickham, M Averick, J Bryan, W Chang, L D McGowan, R François, G Grolemund, A Hayes, L Henry, J Hester, M Kuhn, T L Pedersen, E Miller, S M Bache, K Müller, J Ooms, D Robinson, D P Seidel, V Spinu, K Takahashi, D Vaughan, C Wilke, K Woo and H Yutani (2019) Welcome to the tidyverse *Journal of Open Source Software* **4** (43) 1686 DOI: https://doi.org/10.21105/joss.01686.
  
# Information on current R session
  
```{r session, echo = FALSE}
sessionInfo()
```